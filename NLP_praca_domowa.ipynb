{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Opis problemu\n",
    "\n",
    "Znajdź dowolny zbiór danych (dozwolone języki: angielski, hiszpański, polski, szwedzki) (poza IMDB oraz zbiorami wykorzystywanymi na zajęciach) do analizy sentymentu.\n",
    "Zbiór może mieć 2 lub 3 klasy.\n",
    "\n",
    "Następnie:\n",
    "1. Oczyść dane i zaprezentuj rozkład klas\n",
    "2. Zbuduj model analizy sentymenu:\n",
    "  - z wykorzystaniem sieci rekurencyjnej (LSTM/GRU/sieć dwukierunkowa) innej niż podstawowe RNN\n",
    "  - z wykorzystaniem sieci CNN\n",
    "  - z podstawiemiem pre-trained word embeddingów\n",
    "  - z fine-tuningiem modelu języka (poza podstawowym BERTem)\n",
    "\n",
    "3. Stwórz funkcję, która będzie korzystała z wytrenowanego modelu i zwracała wynik dla przekazanego pojedynczego zdania (zdań) w postaci komunikatu informującego użytkownika, czy tekst jest nacechowany negatywnie, pozytywnie (czy neutralnie w przypadku 3 klas).\n",
    "\n",
    "4. Gotowe rozwiązanie zamieść na GitHubie z README. W README zawrzyj: informacje o danych - ich pochodzenie, oraz opis wybranego modelu i instrukcje korzystania z plików.\n",
    "5. W assigmnencie w Teamsach wrzuć link do repo z rozwiązaniem. W przypadku prywatnego repo upewnij się, że będzie ono widoczne dla `dwnuk@pjwstk.edu.pl`.\n",
    "\n",
    "**TERMIN**: jak w Teamsach"
   ],
   "metadata": {
    "id": "OYpJoHsns0aA"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T08:29:00.158161Z",
     "start_time": "2024-01-24T08:29:00.142778Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# todo: opisać zbió® danych\n",
    "\n",
    "###############\n",
    "# Load data\n",
    "###############\n",
    "file_path = 'data.csv'\n",
    "data = pd.read_csv(file_path).head(5000)\n",
    "data = data.drop(columns=['index'])\n",
    "data['tweets'] = data['tweets'].str.replace('[^a-zA-Z\\s]', '').str.lower()\n",
    "\n",
    "###############\n",
    "# Prepare datasets\n",
    "###############\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['tweets'], data['labels'], test_size=0.2, random_state=42)\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "KNsVcEZ1sx5b",
    "ExecuteTime": {
     "end_time": "2024-01-24T08:29:00.634141Z",
     "start_time": "2024-01-24T08:29:00.150372Z"
    }
   },
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "###############\n",
    "# Encoding lavels\n",
    "###############\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T08:29:00.643106Z",
     "start_time": "2024-01-24T08:29:00.635380Z"
    }
   },
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "###############\n",
    "# Making tokens\n",
    "###############\n",
    "def tokenize(text):\n",
    "    return text.split()\n",
    "\n",
    "word_counts = Counter()\n",
    "for text in X_train:\n",
    "    word_counts.update(tokenize(text))\n",
    "vocab = {word: i+1 for i, word in enumerate(word_counts)} # +1 dla paddingu\n",
    "vocab['<pad>'] = 0\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T08:29:00.656398Z",
     "start_time": "2024-01-24T08:29:00.650051Z"
    }
   },
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# creating datasets \n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, texts, labels, vocab):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        numericalized_text = [self.vocab.get(word, 0) for word in tokenize(text)]  # 0 dla nieznanych slow\n",
    "        return torch.tensor(numericalized_text, dtype=torch.long), label\n",
    "\n",
    "def collate_batch(batch):\n",
    "    text_list, labels = zip(*batch)\n",
    "    text_tensor = pad_sequence([text for text, _ in batch], batch_first=True, padding_value=0)\n",
    "    labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "    return text_tensor, labels_tensor\n",
    "\n",
    "batch_size = 256\n",
    "train_dataset = CustomDataset(X_train, y_train_encoded, vocab)\n",
    "test_dataset = CustomDataset(X_test, y_test_encoded, vocab)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T08:29:00.658656Z",
     "start_time": "2024-01-24T08:29:00.655543Z"
    }
   },
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# model LSTM\n",
    "class SentimentAnalysisLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(SentimentAnalysisLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1)\n",
    "        hidden = self.dropout(hidden)\n",
    "        return self.fc(hidden)\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 128\n",
    "hidden_dim = 256\n",
    "output_dim = len(le.classes_)\n",
    "\n",
    "model = SentimentAnalysisLSTM(vocab_size, embedding_dim, hidden_dim, output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T08:29:00.687306Z",
     "start_time": "2024-01-24T08:29:00.660088Z"
    }
   },
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, device=None):\n",
    "    model.train()\n",
    "    for text, labels in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(text)\n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def evaluate(model, iterator, criterion=None, device=None):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for text, labels in iterator:\n",
    "            predictions = model(text)\n",
    "            all_predictions.extend(predictions.argmax(dim=1).tolist())\n",
    "            all_labels.extend(labels.tolist())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    return accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T08:37:21.267637Z",
     "start_time": "2024-01-24T08:37:21.259949Z"
    }
   },
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Dur: 1.566s\n",
      "\tTest Accuracy: 49.70%\n",
      "Epoch: 2 | Dur: 1.492s\n",
      "\tTest Accuracy: 53.50%\n",
      "Epoch: 3 | Dur: 1.462s\n",
      "\tTest Accuracy: 58.00%\n",
      "Epoch: 4 | Dur: 1.488s\n",
      "\tTest Accuracy: 59.30%\n",
      "Epoch: 5 | Dur: 1.498s\n",
      "\tTest Accuracy: 62.60%\n",
      "Epoch: 6 | Dur: 1.919s\n",
      "\tTest Accuracy: 61.20%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[71], line 34\u001B[0m\n\u001B[1;32m     32\u001B[0m s_t \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m     33\u001B[0m \u001B[38;5;66;03m# print(\"E\", epoch)\u001B[39;00m\n\u001B[0;32m---> 34\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;66;03m# print(1)\u001B[39;00m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;66;03m# train_accuracy = evaluate(model, train_loader, criterion)\u001B[39;00m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;66;03m# print(2)\u001B[39;00m\n\u001B[1;32m     38\u001B[0m test_accuracy \u001B[38;5;241m=\u001B[39m evaluate(model, test_loader)\n",
      "Cell \u001B[0;32mIn[71], line 9\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(model, iterator, optimizer, criterion, device)\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m text, labels \u001B[38;5;129;01min\u001B[39;00m iterator:\n\u001B[1;32m      8\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m----> 9\u001B[0m     predictions \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion(predictions, labels)\n\u001B[1;32m     11\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/zum-1-GR6G5q4i-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[0;32mIn[70], line 32\u001B[0m, in \u001B[0;36mTextCNN.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     30\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membedding(x)  \u001B[38;5;66;03m# [batch size, sent len, emb dim]\u001B[39;00m\n\u001B[1;32m     31\u001B[0m x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m1\u001B[39m)  \u001B[38;5;66;03m# [batch size, 1, sent len, emb dim]\u001B[39;00m\n\u001B[0;32m---> 32\u001B[0m x \u001B[38;5;241m=\u001B[39m [torch\u001B[38;5;241m.\u001B[39mrelu(conv(x))\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m3\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m conv \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconvs]\n\u001B[1;32m     33\u001B[0m x \u001B[38;5;241m=\u001B[39m [torch\u001B[38;5;241m.\u001B[39mmax_pool1d(conv, conv\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m2\u001B[39m])\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m2\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m conv \u001B[38;5;129;01min\u001B[39;00m x]\n\u001B[1;32m     34\u001B[0m x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat(x, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "Cell \u001B[0;32mIn[70], line 32\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     30\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membedding(x)  \u001B[38;5;66;03m# [batch size, sent len, emb dim]\u001B[39;00m\n\u001B[1;32m     31\u001B[0m x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m1\u001B[39m)  \u001B[38;5;66;03m# [batch size, 1, sent len, emb dim]\u001B[39;00m\n\u001B[0;32m---> 32\u001B[0m x \u001B[38;5;241m=\u001B[39m [torch\u001B[38;5;241m.\u001B[39mrelu(\u001B[43mconv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m3\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m conv \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconvs]\n\u001B[1;32m     33\u001B[0m x \u001B[38;5;241m=\u001B[39m [torch\u001B[38;5;241m.\u001B[39mmax_pool1d(conv, conv\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m2\u001B[39m])\u001B[38;5;241m.\u001B[39msqueeze(\u001B[38;5;241m2\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m conv \u001B[38;5;129;01min\u001B[39;00m x]\n\u001B[1;32m     34\u001B[0m x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat(x, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/zum-1-GR6G5q4i-py3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/zum-1-GR6G5q4i-py3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py:463\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    462\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 463\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_conv_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/zum-1-GR6G5q4i-py3.9/lib/python3.9/site-packages/torch/nn/modules/conv.py:459\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    455\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    456\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[1;32m    457\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    458\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[0;32m--> 459\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    460\u001B[0m \u001B[43m                \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Training loop\n",
    "N_EPOCHS = 10\n",
    "for epoch in range(N_EPOCHS):\n",
    "    s_t = time.time()\n",
    "    # print(\"E\", epoch)\n",
    "    train(model, train_loader, optimizer, criterion)\n",
    "    # print(1)\n",
    "    # train_accuracy = evaluate(model, train_loader, criterion)\n",
    "    # print(2)\n",
    "    test_accuracy = evaluate(model, test_loader)\n",
    "    print(f\"Epoch: {epoch+1} | Dur: {time.time() - s_t:.3f}s\")\n",
    "    # print(f'\\tTrain Accuracy: {train_accuracy * 100:.2f}%')\n",
    "    print(f'\\tTest Accuracy: {test_accuracy * 100:.2f}%')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T08:37:20.273470Z",
     "start_time": "2024-01-24T08:37:10.171171Z"
    }
   },
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "SentimentAnalysisLSTM(\n  (embedding): Embedding(17372, 128, padding_idx=0)\n  (lstm): LSTM(128, 256, batch_first=True, bidirectional=True)\n  (fc): Linear(in_features=512, out_features=3, bias=True)\n  (dropout): Dropout(p=0.5, inplace=False)\n)"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "torch.save(model.state_dict(), 'models/lstm.pth')\n",
    "# Recreate the model (ensure the class definition is available)\n",
    "model = SentimentAnalysisLSTM(vocab_size, embedding_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Load the saved state dictionary\n",
    "model.load_state_dict(torch.load('models/lstm.pth'))\n",
    "\n",
    "# Don't forget to set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T08:29:48.190728Z",
     "start_time": "2024-01-24T08:29:48.155501Z"
    }
   },
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Dur: 1.653s\n",
      "\tTest Accuracy: 48.90%\n",
      "Epoch: 2 | Dur: 1.470s\n",
      "\tTest Accuracy: 57.90%\n",
      "Epoch: 3 | Dur: 1.474s\n",
      "\tTest Accuracy: 54.00%\n",
      "Epoch: 4 | Dur: 1.433s\n",
      "\tTest Accuracy: 56.90%\n",
      "Epoch: 5 | Dur: 1.454s\n",
      "\tTest Accuracy: 60.90%\n",
      "Epoch: 6 | Dur: 1.449s\n",
      "\tTest Accuracy: 62.10%\n",
      "Epoch: 7 | Dur: 1.456s\n",
      "\tTest Accuracy: 62.70%\n",
      "Epoch: 8 | Dur: 1.472s\n",
      "\tTest Accuracy: 60.90%\n",
      "Epoch: 9 | Dur: 1.494s\n",
      "\tTest Accuracy: 61.10%\n",
      "Epoch: 10 | Dur: 1.488s\n",
      "\tTest Accuracy: 64.30%\n",
      "Epoch: 11 | Dur: 1.481s\n",
      "\tTest Accuracy: 63.50%\n",
      "Epoch: 12 | Dur: 1.511s\n",
      "\tTest Accuracy: 63.10%\n",
      "Epoch: 13 | Dur: 1.488s\n",
      "\tTest Accuracy: 64.60%\n",
      "Epoch: 14 | Dur: 1.813s\n",
      "\tTest Accuracy: 64.10%\n",
      "Epoch: 15 | Dur: 1.514s\n",
      "\tTest Accuracy: 64.50%\n",
      "Epoch: 16 | Dur: 1.607s\n",
      "\tTest Accuracy: 64.30%\n",
      "Epoch: 17 | Dur: 1.485s\n",
      "\tTest Accuracy: 64.80%\n",
      "Epoch: 18 | Dur: 1.494s\n",
      "\tTest Accuracy: 63.30%\n",
      "Epoch: 19 | Dur: 1.653s\n",
      "\tTest Accuracy: 64.20%\n",
      "Epoch: 20 | Dur: 1.529s\n",
      "\tTest Accuracy: 64.70%\n",
      "Epoch: 21 | Dur: 1.495s\n",
      "\tTest Accuracy: 62.90%\n",
      "Epoch: 22 | Dur: 1.488s\n",
      "\tTest Accuracy: 65.30%\n",
      "Epoch: 23 | Dur: 1.480s\n",
      "\tTest Accuracy: 63.20%\n",
      "Epoch: 24 | Dur: 1.500s\n",
      "\tTest Accuracy: 64.20%\n",
      "Epoch: 25 | Dur: 1.506s\n",
      "\tTest Accuracy: 63.90%\n",
      "Epoch: 26 | Dur: 1.493s\n",
      "\tTest Accuracy: 64.10%\n",
      "Epoch: 27 | Dur: 1.482s\n",
      "\tTest Accuracy: 64.60%\n",
      "Epoch: 28 | Dur: 1.559s\n",
      "\tTest Accuracy: 64.30%\n",
      "Epoch: 29 | Dur: 1.522s\n",
      "\tTest Accuracy: 64.30%\n",
      "Epoch: 30 | Dur: 1.526s\n",
      "\tTest Accuracy: 65.50%\n",
      "Epoch: 31 | Dur: 1.595s\n",
      "\tTest Accuracy: 64.50%\n",
      "Epoch: 32 | Dur: 1.494s\n",
      "\tTest Accuracy: 64.30%\n",
      "Epoch: 33 | Dur: 1.726s\n",
      "\tTest Accuracy: 64.60%\n",
      "Epoch: 34 | Dur: 1.520s\n",
      "\tTest Accuracy: 65.20%\n",
      "Epoch: 35 | Dur: 1.506s\n",
      "\tTest Accuracy: 64.30%\n",
      "Epoch: 36 | Dur: 1.483s\n",
      "\tTest Accuracy: 64.10%\n",
      "Epoch: 37 | Dur: 1.479s\n",
      "\tTest Accuracy: 63.70%\n",
      "Epoch: 38 | Dur: 1.480s\n",
      "\tTest Accuracy: 64.30%\n",
      "Epoch: 39 | Dur: 1.491s\n",
      "\tTest Accuracy: 64.40%\n",
      "Epoch: 40 | Dur: 1.498s\n",
      "\tTest Accuracy: 64.50%\n",
      "Epoch: 41 | Dur: 1.484s\n",
      "\tTest Accuracy: 64.00%\n",
      "Epoch: 42 | Dur: 1.481s\n",
      "\tTest Accuracy: 64.10%\n",
      "Epoch: 43 | Dur: 1.474s\n",
      "\tTest Accuracy: 64.20%\n",
      "Epoch: 44 | Dur: 1.474s\n",
      "\tTest Accuracy: 63.90%\n",
      "Epoch: 45 | Dur: 1.501s\n",
      "\tTest Accuracy: 64.50%\n",
      "Epoch: 46 | Dur: 1.483s\n",
      "\tTest Accuracy: 65.10%\n",
      "Epoch: 47 | Dur: 1.549s\n",
      "\tTest Accuracy: 65.10%\n",
      "Epoch: 48 | Dur: 1.547s\n",
      "\tTest Accuracy: 63.70%\n",
      "Epoch: 49 | Dur: 1.572s\n",
      "\tTest Accuracy: 64.30%\n",
      "Epoch: 50 | Dur: 1.513s\n",
      "\tTest Accuracy: 64.40%\n",
      "Epoch: 51 | Dur: 1.500s\n",
      "\tTest Accuracy: 63.90%\n",
      "Epoch: 52 | Dur: 1.518s\n",
      "\tTest Accuracy: 64.40%\n",
      "Epoch: 53 | Dur: 1.504s\n",
      "\tTest Accuracy: 64.40%\n",
      "Epoch: 54 | Dur: 1.607s\n",
      "\tTest Accuracy: 63.90%\n",
      "Epoch: 55 | Dur: 1.488s\n",
      "\tTest Accuracy: 63.90%\n",
      "Epoch: 56 | Dur: 1.605s\n",
      "\tTest Accuracy: 64.60%\n",
      "Epoch: 57 | Dur: 1.795s\n",
      "\tTest Accuracy: 64.30%\n",
      "Epoch: 58 | Dur: 1.719s\n",
      "\tTest Accuracy: 64.60%\n",
      "Epoch: 59 | Dur: 1.546s\n",
      "\tTest Accuracy: 64.00%\n",
      "Epoch: 60 | Dur: 1.518s\n",
      "\tTest Accuracy: 63.50%\n",
      "Epoch: 61 | Dur: 1.443s\n",
      "\tTest Accuracy: 65.30%\n",
      "Epoch: 62 | Dur: 1.480s\n",
      "\tTest Accuracy: 64.20%\n",
      "Epoch: 63 | Dur: 1.495s\n",
      "\tTest Accuracy: 65.30%\n",
      "Epoch: 64 | Dur: 1.456s\n",
      "\tTest Accuracy: 64.10%\n",
      "Epoch: 65 | Dur: 1.498s\n",
      "\tTest Accuracy: 64.30%\n",
      "Epoch: 66 | Dur: 1.464s\n",
      "\tTest Accuracy: 65.60%\n",
      "Epoch: 67 | Dur: 1.491s\n",
      "\tTest Accuracy: 65.20%\n",
      "Epoch: 68 | Dur: 1.478s\n",
      "\tTest Accuracy: 64.70%\n",
      "Epoch: 69 | Dur: 1.482s\n",
      "\tTest Accuracy: 63.20%\n",
      "Epoch: 70 | Dur: 1.466s\n",
      "\tTest Accuracy: 63.90%\n",
      "Epoch: 71 | Dur: 1.455s\n",
      "\tTest Accuracy: 63.70%\n",
      "Epoch: 72 | Dur: 1.458s\n",
      "\tTest Accuracy: 64.60%\n",
      "Epoch: 73 | Dur: 1.479s\n",
      "\tTest Accuracy: 63.30%\n",
      "Epoch: 74 | Dur: 1.461s\n",
      "\tTest Accuracy: 64.70%\n",
      "Epoch: 75 | Dur: 1.468s\n",
      "\tTest Accuracy: 61.90%\n",
      "Epoch: 76 | Dur: 1.497s\n",
      "\tTest Accuracy: 63.50%\n",
      "Epoch: 77 | Dur: 1.505s\n",
      "\tTest Accuracy: 64.80%\n",
      "Epoch: 78 | Dur: 1.485s\n",
      "\tTest Accuracy: 61.90%\n",
      "Epoch: 79 | Dur: 1.479s\n",
      "\tTest Accuracy: 63.50%\n",
      "Epoch: 80 | Dur: 1.447s\n",
      "\tTest Accuracy: 62.80%\n",
      "Epoch: 81 | Dur: 1.452s\n",
      "\tTest Accuracy: 64.00%\n",
      "Epoch: 82 | Dur: 1.464s\n",
      "\tTest Accuracy: 63.20%\n",
      "Epoch: 83 | Dur: 1.454s\n",
      "\tTest Accuracy: 62.30%\n",
      "Epoch: 84 | Dur: 1.497s\n",
      "\tTest Accuracy: 62.10%\n",
      "Epoch: 85 | Dur: 1.533s\n",
      "\tTest Accuracy: 62.80%\n",
      "Epoch: 86 | Dur: 1.479s\n",
      "\tTest Accuracy: 63.20%\n",
      "Epoch: 87 | Dur: 1.490s\n",
      "\tTest Accuracy: 63.10%\n",
      "Epoch: 88 | Dur: 1.460s\n",
      "\tTest Accuracy: 63.30%\n",
      "Epoch: 89 | Dur: 1.468s\n",
      "\tTest Accuracy: 63.10%\n",
      "Epoch: 90 | Dur: 1.616s\n",
      "\tTest Accuracy: 63.50%\n",
      "Epoch: 91 | Dur: 1.541s\n",
      "\tTest Accuracy: 63.00%\n",
      "Epoch: 92 | Dur: 1.728s\n",
      "\tTest Accuracy: 60.80%\n",
      "Epoch: 93 | Dur: 1.600s\n",
      "\tTest Accuracy: 63.20%\n",
      "Epoch: 94 | Dur: 1.663s\n",
      "\tTest Accuracy: 62.70%\n",
      "Epoch: 95 | Dur: 1.466s\n",
      "\tTest Accuracy: 63.50%\n",
      "Epoch: 96 | Dur: 1.501s\n",
      "\tTest Accuracy: 62.60%\n",
      "Epoch: 97 | Dur: 1.468s\n",
      "\tTest Accuracy: 62.30%\n",
      "Epoch: 98 | Dur: 1.440s\n",
      "\tTest Accuracy: 64.60%\n",
      "Epoch: 99 | Dur: 1.439s\n",
      "\tTest Accuracy: 62.10%\n",
      "Epoch: 100 | Dur: 1.431s\n",
      "\tTest Accuracy: 62.40%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "device = torch.device('cpu')\n",
    "\n",
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout):\n",
    "        super(TextCNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(fs, embedding_dim))\n",
    "            for fs in filter_sizes\n",
    "        ])\n",
    "\n",
    "        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # [batch size, sent len, emb dim]\n",
    "        x = x.unsqueeze(1)  # [batch size, 1, sent len, emb dim]\n",
    "        x = [torch.relu(conv(x)).squeeze(3) for conv in self.convs]\n",
    "        x = [torch.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in x]\n",
    "        x = torch.cat(x, dim=1)\n",
    "        x = self.dropout(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 100\n",
    "n_filters = 100\n",
    "filter_sizes = [2, 3, 4]\n",
    "output_dim = len(le.classes_)\n",
    "dropout = 0.5\n",
    "\n",
    "model = TextCNN(vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout).to(device)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "N_EPOCHS = 100\n",
    "for epoch in range(N_EPOCHS):\n",
    "    s_t = time.time()\n",
    "    train(model, train_loader, optimizer, criterion, device)\n",
    "    # train_accuracy = evaluate(model, train_loader, criterion, device)\n",
    "    test_accuracy = evaluate(model, test_loader, criterion, device)\n",
    "    print(f\"Epoch: {epoch+1} | Dur: {time.time() - s_t:.3f}s\")\n",
    "    # print(f'\\tTrain Accuracy: {train_accuracy * 100:.2f}%')\n",
    "    print(f'\\tTest Accuracy: {test_accuracy * 100:.2f}%')\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T08:47:57.240719Z",
     "start_time": "2024-01-24T08:45:25.918041Z"
    }
   },
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'glove.6B.100d.txt'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[78], line 24\u001B[0m\n\u001B[1;32m     21\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m embeddings_dict\n\u001B[1;32m     23\u001B[0m glove_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mglove.6B.100d.txt\u001B[39m\u001B[38;5;124m'\u001B[39m  \u001B[38;5;66;03m# Update this path\u001B[39;00m\n\u001B[0;32m---> 24\u001B[0m glove_embeddings \u001B[38;5;241m=\u001B[39m \u001B[43mload_glove_embeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43mglove_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;66;03m# Prepare Data\u001B[39;00m\n\u001B[1;32m     27\u001B[0m X_train, X_test, y_train, y_test \u001B[38;5;241m=\u001B[39m train_test_split(data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtweets\u001B[39m\u001B[38;5;124m'\u001B[39m], data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabels\u001B[39m\u001B[38;5;124m'\u001B[39m], test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n",
      "Cell \u001B[0;32mIn[78], line 15\u001B[0m, in \u001B[0;36mload_glove_embeddings\u001B[0;34m(path)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_glove_embeddings\u001B[39m(path):\n\u001B[1;32m     14\u001B[0m     embeddings_dict \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m---> 15\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mutf8\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m     16\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m f:\n\u001B[1;32m     17\u001B[0m             values \u001B[38;5;241m=\u001B[39m line\u001B[38;5;241m.\u001B[39msplit()\n",
      "File \u001B[0;32m~/Library/Caches/pypoetry/virtualenvs/zum-1-GR6G5q4i-py3.9/lib/python3.9/site-packages/IPython/core/interactiveshell.py:310\u001B[0m, in \u001B[0;36m_modified_open\u001B[0;34m(file, *args, **kwargs)\u001B[0m\n\u001B[1;32m    303\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[1;32m    304\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    305\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    306\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    307\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    308\u001B[0m     )\n\u001B[0;32m--> 310\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'glove.6B.100d.txt'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import Counter\n",
    "\n",
    "# Assuming you have loaded your dataset into a DataFrame `data`\n",
    "\n",
    "# Load GloVe Embeddings\n",
    "def load_glove_embeddings(path):\n",
    "    embeddings_dict = {}\n",
    "    with open(path, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = torch.tensor([float(val) for val in values[1:]], dtype=torch.float)\n",
    "            embeddings_dict[word] = vector\n",
    "    return embeddings_dict\n",
    "\n",
    "glove_path = 'glove.6B.100d.txt'  # Update this path\n",
    "glove_embeddings = load_glove_embeddings(glove_path)\n",
    "\n",
    "# Prepare Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['tweets'], data['labels'], test_size=0.2, random_state=42)\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded = le.transform(y_test)\n",
    "\n",
    "# Build Vocabulary\n",
    "vocab = {\"<PAD>\": 0}\n",
    "for text in X_train:\n",
    "    for word in text.split():\n",
    "        if word not in vocab:\n",
    "            vocab[word] = len(vocab)\n",
    "\n",
    "# Prepare Embedding Matrix\n",
    "embedding_dim = 100  # Dimension of GloVe vectors you are using\n",
    "embedding_matrix = torch.zeros((len(vocab), embedding_dim))\n",
    "for word, idx in vocab.items():\n",
    "    embedding_vector = glove_embeddings.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[idx] = embedding_vector\n",
    "    else:\n",
    "        embedding_matrix[idx] = torch.randn(embedding_dim)  # Random vector for unknown words\n",
    "\n",
    "# Model\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, output_dim):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.embedding = nn.Embedding.from_pretrained(embedding_matrix, freeze=True)\n",
    "        self.fc = nn.Linear(embedding_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        pooled = torch.mean(embedded, dim=1)  # Average pooling\n",
    "        return self.fc(pooled)\n",
    "\n",
    "# Instantiate model, loss, optimizer\n",
    "model = SimpleNN(len(vocab), embedding_dim, len(le.classes_))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Data Loaders\n",
    "# Assuming you have defined CustomDataset and collate_fn appropriately\n",
    "train_dataset = CustomDataset(X_train, y_train_encoded, vocab)\n",
    "test_dataset = CustomDataset(X_test, y_test_encoded, vocab)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(10):\n",
    "    for texts, labels in train_loader:\n",
    "        # Your training loop: forward pass, compute loss, backward pass\n",
    "        pass\n",
    "\n",
    "    # Evaluation on the test set\n",
    "    # ...\n",
    "\n",
    "# Save your model if needed\n",
    "# torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-24T08:56:39.828630Z",
     "start_time": "2024-01-24T08:56:39.744535Z"
    }
   },
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
